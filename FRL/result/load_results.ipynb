{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy import stats\n",
    "from sklearn.metrics import log_loss\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def summarize_rule(rule_ls,show):\n",
    "    string_rule = rule_ls\n",
    "    group = []\n",
    "    count = []\n",
    "\n",
    "    for i in range(len(string_rule)):\n",
    "        rule = string_rule[i]\n",
    "        for k in range(len(rule)):\n",
    "            if len(rule[k])>1:\n",
    "                rule[k] = list(np.sort(rule[k]))\n",
    "        if rule not in group:\n",
    "            group.append(rule)\n",
    "            count.append(1)\n",
    "        else:\n",
    "            count[group.index(rule)] += 1\n",
    "    if show==True:\n",
    "        for i in range(len(group)):\n",
    "            print(group[i],\"\\t\",count[i]/len(string_rule)*100,\"%\")\n",
    "    else:\n",
    "        return group, np.array(count)/len(string_rule)\n",
    "            \n",
    "def get_result(string,show=True):\n",
    "    file = string\n",
    "    with open(file+'.pkl', 'rb') as f:\n",
    "        result = pickle.load(f)\n",
    "    rule_nonstab = result[0]\n",
    "    rule_stab = [item[-1] for item in result[1]]\n",
    "    n_all = [item[-1] for item in result[2]]\n",
    "    group_all = result[3]\n",
    "    len_all = result[4]\n",
    "    \n",
    "    if show == True:\n",
    "#         print(len(rule_nonstab))\n",
    "        print(\"non stablize:\")\n",
    "        summarize_rule(rule_nonstab,show)\n",
    "        print(\"\\n\")\n",
    "        print(\"stablize:\")\n",
    "        summarize_rule(rule_stab,show)\n",
    "#         print(n_all)\n",
    "    else:\n",
    "#         print(string)\n",
    "#         print(len(rule_nonstab))\n",
    "        group1, percent1 = summarize_rule(rule_nonstab,show)\n",
    "        group2, percent2 = summarize_rule(rule_stab,show)\n",
    "        \n",
    "        return percent1, percent2\n",
    "    \n",
    "def extract_data(string_ls,feature,file):\n",
    "    percent1_ls = []\n",
    "    percent2_ls = []\n",
    "    for string in string_ls:\n",
    "        percent1, percent2 = get_result(string,False)\n",
    "        percent1_ls.append(np.sort(percent1)[::-1])\n",
    "        percent2_ls.append(np.sort(percent2)[::-1])\n",
    "\n",
    "    df = pd.DataFrame(data={'feature': [], 'rule': [], 'percent':[],'type':[]})\n",
    "\n",
    "    for k in range(len(feature)):\n",
    "        percent1 = percent1_ls[k]\n",
    "        for i in range(len(percent1)):\n",
    "            df.loc[len(df.index)] = [feature[k],i,percent1[i],\"Non-Stab\"]\n",
    "\n",
    "        percent2 = percent2_ls[k]\n",
    "        for i in range(len(percent2)):\n",
    "            df.loc[len(df.index)] = [feature[k],i,percent2[i],\"Stab\"]\n",
    "\n",
    "    df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sim\n",
    "string_ls = [\"FRL_data1_n_sim_1_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_2_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_5_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_7_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\"]\n",
    "feature = [1,2,5,7,10]\n",
    "file = \"FRL_data1_n_sim.csv\"\n",
    "extract_data(string_ls,feature,file)\n",
    "\n",
    "# len_max\n",
    "string_ls = [\"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_4\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_5\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_6\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_7\"]\n",
    "feature = [3,4,5,6,7]\n",
    "file = \"FRL_data1_len_max.csv\"\n",
    "extract_data(string_ls,feature,file)\n",
    "\n",
    "# nmax\n",
    "string_ls = [\"FRL_data1_n_sim_10_n_init_1000_nmax_10000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_25000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_50000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data1_n_sim_10_n_init_1000_nmax_250000_n_sample_1000_len_max_3\"]\n",
    "feature = [10000,25000,50000,100000,250000]\n",
    "file = \"FRL_data1_nmax.csv\"\n",
    "extract_data(string_ls,feature,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non stablize:\n",
      "[['Age_geq_60', 'IllDefinedMargin'], ['IrregularShape'], ['SpiculatedMargin']] \t 21.0 %\n",
      "[['Age_geq_60', 'SpiculatedMargin'], ['Age_geq_60', 'IllDefinedMargin'], ['IrregularShape']] \t 20.0 %\n",
      "[['IrregularShape'], ['Age_geq_60', 'IllDefinedMargin'], ['SpiculatedMargin']] \t 19.0 %\n",
      "[['IrregularShape'], ['Age_geq_60', 'IllDefinedMargin'], ['Density_geq_2', 'SpiculatedMargin']] \t 11.0 %\n",
      "[['IrregularShape'], ['Density_geq_2', 'SpiculatedMargin'], ['Age_geq_60']] \t 8.0 %\n",
      "[['Age_geq_60', 'IllDefinedMargin'], ['IrregularShape'], ['Density_geq_2', 'SpiculatedMargin']] \t 3.0 %\n",
      "[['IrregularShape'], ['SpiculatedMargin'], ['Age_geq_60']] \t 3.0 %\n",
      "[['Age_geq_60', 'SpiculatedMargin'], ['IrregularShape'], ['Age_geq_60', 'IllDefinedMargin']] \t 12.0 %\n",
      "[['Age_geq_60', 'IllDefinedMargin'], ['Age_geq_60', 'SpiculatedMargin'], ['IrregularShape']] \t 2.0 %\n",
      "[['IrregularShape'], ['Age_geq_60', 'Density_geq_2'], ['SpiculatedMargin']] \t 1.0 %\n",
      "\n",
      "\n",
      "stablize:\n",
      "[['IrregularShape'], ['Age_geq_60', 'IllDefinedMargin'], ['SpiculatedMargin']] \t 94.0 %\n",
      "[['Age_geq_60', 'IllDefinedMargin'], ['IrregularShape'], ['SpiculatedMargin']] \t 1.0 %\n",
      "[['Age_geq_60', 'SpiculatedMargin'], ['Age_geq_60', 'IllDefinedMargin'], ['IrregularShape']] \t 5.0 %\n"
     ]
    }
   ],
   "source": [
    "get_result(\"FRL_data1_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non stablize:\n",
      "[['worst area_1', 'worst radius_1'], ['worst concave points_1'], ['worst concavity_1']] \t 63.0 %\n",
      "[['worst area_1'], ['worst concave points_1'], ['worst concavity_1']] \t 21.0 %\n",
      "[['worst area_1', 'worst perimeter_1'], ['worst concave points_1'], ['worst concavity_1']] \t 9.0 %\n",
      "[['worst radius_1'], ['worst concave points_1'], ['worst concavity_1']] \t 3.0 %\n",
      "[['worst area_1', 'worst radius_1'], ['worst concavity_1'], ['worst concave points_1']] \t 3.0 %\n",
      "[['worst perimeter_1', 'worst radius_1'], ['worst concave points_1'], ['worst concavity_1']] \t 1.0 %\n",
      "\n",
      "\n",
      "stablize:\n",
      "[['worst area_1', 'worst radius_1'], ['worst concave points_1'], ['worst concavity_1']] \t 100.0 %\n"
     ]
    }
   ],
   "source": [
    "get_result(\"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sim\n",
    "string_ls = [\"FRL_data2_n_sim_1_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_2_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_5_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_7_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\"]\n",
    "feature = [1,2,5,7,10]\n",
    "file = \"FRL_data2_n_sim.csv\"\n",
    "extract_data(string_ls,feature,file)\n",
    "\n",
    "# len_max\n",
    "string_ls = [\"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_4\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_5\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_6\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_7\"]\n",
    "feature = [3,4,5,6,7]\n",
    "file = \"FRL_data2_len_max.csv\"\n",
    "extract_data(string_ls,feature,file)\n",
    "\n",
    "\n",
    "# nmax\n",
    "string_ls = [\"FRL_data2_n_sim_10_n_init_1000_nmax_10000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_25000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_50000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_100000_n_sample_1000_len_max_3\",\n",
    "            \"FRL_data2_n_sim_10_n_init_1000_nmax_250000_n_sample_1000_len_max_3\"]\n",
    "feature = [10000,25000,50000,100000,250000]\n",
    "file = \"FRL_data2_nmax.csv\"\n",
    "extract_data(string_ls,feature,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_distill",
   "language": "python",
   "name": "stable_distill"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
